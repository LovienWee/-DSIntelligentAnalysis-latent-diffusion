# configs/latent-diffusion/ocean_ldm_inpaint.yaml
model:
  base_learning_rate: 1.0e-4
  target: ldm.models.diffusion.ocean_inpaint_ldm.OceanInpaintLDM
  params:
    conditioning_key: concat
    linear_start: 0.00085
    linear_end: 0.012
    num_timesteps_cond: 1
    log_every_t: 100
    timesteps: 1000
    first_stage_key: image
    monitor: "val/loss_simple_ema"

    first_stage_config:
      target: ldm.models.autoencoder.AutoencoderKL
      params:
        embed_dim: 4
        ddconfig:
          double_z: true
          z_channels: 4
          resolution: 128
          in_channels: 4          # <== 与你的 VAE 输入通道一致（若你用6通道，这里改6）
          out_ch: 4               # <== 同上
          ch: 128
          ch_mult: [1, 2, 4, 4]
          num_res_blocks: 2
          attn_resolutions: []
          dropout: 0.0
        lossconfig:
          target: ldm.modules.losses.LPIPSWithDiscriminator
          params:
            disc_start: 50001
            disc_weight: 0.5
            disc_in_channels: 4
            perceptual_weight: 0.0
        ckpt_path: "REPLACE_WITH_YOUR_AUTOENCODER_CKPT.ckpt"  # <== 改成你训好的 VAE ckpt

    unet_config:
      target: ldm.modules.diffusionmodules.openaimodel.UNetModel
      params:
        image_size: 32
        in_channels: 8        # 2 * z_channels (默认 zc=4 -> 8)。若你改 zc，请同步改 2*zc
        out_channels: 4       # 预测噪声通道 = z_channels
        model_channels: 320
        attention_resolutions: [4, 2, 1]
        num_res_blocks: 2
        channel_mult: [1, 2, 4, 4]
        num_heads: 8
        use_scale_shift_norm: true
        resblock_updown: true
        use_new_attention_order: false

    loss_type: l1
    use_ema: true

data:
  target: ldm.data.base.DataModuleFromConfig
  params:
    batch_size: 8
    num_workers: 8
    train:
      target: ldm.data.ocean_inpaint.make_inpaint_dataloader
      params:
        nc_paths:
          - oceandata/IndianOcean/indianOcean.nc
          - oceandata/SouthChinaSea/southChinaSea.nc
        split_json: oceandata/Split/SouthChinaSea_split_seq.json
        split_key: train
        crop_size: [128, 128]
        keep_ratio: 0.1
        keep_ratio_jitter: 0.05
        random_flip: true
        batch_size: 8
        num_workers: 8
    validation:
      target: ldm.data.ocean_inpaint.make_inpaint_dataloader
      params:
        nc_paths:
          - oceandata/IndianOcean/indianOcean.nc
          - oceandata/SouthChinaSea/southChinaSea.nc
        split_json: oceandata/Split/SouthChinaSea_split_seq.json
        split_key: val
        crop_size: [128, 128]
        keep_ratio: 0.1
        keep_ratio_jitter: 0.0
        random_flip: false
        batch_size: 8
        num_workers: 8

lightning:
  trainer:
    benchmark: true
    max_epochs: 200
    precision: 16
    devices: 1
    accelerator: gpu
  callbacks:
    - target: pytorch_lightning.callbacks.ModelCheckpoint
      params:
        filename: "ocean_ldm_inpaint-{epoch:02d}-{val/loss_simple_ema:.4f}"
        save_top_k: 3
        monitor: "val/loss_simple_ema"
        mode: "min"
